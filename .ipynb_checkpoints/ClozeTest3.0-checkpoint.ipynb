{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T06:52:02.289013Z",
     "start_time": "2019-12-20T06:52:02.261920Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import glob \n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import operator\n",
    "import collections\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from array import array\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.corpus import treebank\n",
    "from textblob import TextBlob\n",
    "from nltk import Tree\n",
    "from nltk.chunk.regexp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T02:32:25.788330Z",
     "start_time": "2019-12-19T02:32:25.781731Z"
    }
   },
   "outputs": [],
   "source": [
    "def splitSentence(paragraph):\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    sentences = tokenizer.tokenize(paragraph)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:53:59.595230Z",
     "start_time": "2019-12-19T01:53:59.590964Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NONE_STR = '<s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:54:00.001922Z",
     "start_time": "2019-12-19T01:53:59.990024Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_other_letter(line):\n",
    "    punctuation =\"\"\"!\"#$%&\\()*+,./:;<=>?@[\\\\]^_`{|}~\\\\n\"\"\"\n",
    "    re_punctuation =\"[{}]+\".format(punctuation)\n",
    "    line =re.sub(re_punctuation, \"\", line)\n",
    "    return line.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:54:16.005924Z",
     "start_time": "2019-12-19T01:54:15.983995Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_articles(paths):\n",
    "    alllines = []\n",
    "    for path in paths:\n",
    "        filenames = glob.glob(path+\"/*txt\")\n",
    "        for filename in filenames:\n",
    "            with open(filename, 'r', encoding='utf-8') as fpr:\n",
    "                data_raw = json.load(fpr)\n",
    "                article = data_raw['article']\n",
    "                \n",
    "#                 lines = article.split('.')\n",
    "                lines = splitSentence(article)\n",
    "                for line in lines:\n",
    "                    line = delete_other_letter(line)\n",
    "                    alllines.append(line)\n",
    "                \n",
    "    return alllines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T02:33:04.201995Z",
     "start_time": "2019-12-19T02:32:32.649422Z"
    }
   },
   "outputs": [],
   "source": [
    "lines = read_articles(['./RACE/train/high','./RACE/train/middle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T02:33:04.208303Z",
     "start_time": "2019-12-19T02:33:04.204493Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443717\n"
     ]
    }
   ],
   "source": [
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:07.018919Z",
     "start_time": "2019-12-19T01:55:07.012465Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def word_dict(lines):\n",
    "#     word_freq = collections.defaultdict(int)\n",
    "#     for line in lines:\n",
    "#         for w in line.split(): \n",
    "#             word_freq[w] += 1\n",
    "    \n",
    "#     return list(word_freq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:07.245253Z",
     "start_time": "2019-12-19T01:55:07.236275Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_words_matrix(words,lines):                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "#     for line in lines:\n",
    "#         line_words = line.split()\n",
    "#         n = len(line_words)\n",
    "#         for i in range(n-1):\n",
    "#             ww = line_words[i+1]\n",
    "#             i = words.index(line_words[i])\n",
    "#             j = words.index(ww)\n",
    "#             words_matrix[i][j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:07.496795Z",
     "start_time": "2019-12-19T01:55:07.450568Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_dict(lines,n):\n",
    "                \n",
    "    pre_words = collections.defaultdict(int)\n",
    "    be_words = collections.defaultdict(int)\n",
    "    n = n-1\n",
    "    for line in lines:\n",
    "        for k in range(n):\n",
    "            line = NONE_STR+' '+line+' '+NONE_STR\n",
    "        line_words = line.split()\n",
    "        for i in range(len(line_words)-(n-1)):\n",
    "            ngramTemp = ' '.join(line_words[i:i+n])\n",
    "\n",
    "            pre_words[ngramTemp] += 1\n",
    "            be_words[line_words[i]] += 1\n",
    "            \n",
    "    return pre_words,be_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:08.002721Z",
     "start_time": "2019-12-19T01:55:07.994811Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_punctuation(word):\n",
    "    for puc in punctuation_list:\n",
    "        word = word.replace(puc,'')\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T02:16:55.070500Z",
     "start_time": "2019-12-19T02:16:55.064002Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_Chinese_punctuation(content):\n",
    "    content = content.replace('’','\\'')\n",
    "    content = content.replace('”','\"')\n",
    "    content = content.replace('“','\"')\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:08.398514Z",
     "start_time": "2019-12-19T01:55:08.373675Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_options(options_str):\n",
    "    options_str = replace_Chinese_punctuation(options_str)\n",
    "    options = []\n",
    "    opt_rows = options_str.split('#')\n",
    "    for opt in opt_rows:\n",
    "        indexA = opt.find('A.')\n",
    "        indexB = opt.find('B.')\n",
    "        indexC = opt.find('C.')\n",
    "        indexD = opt.find('D.')\n",
    "        As = opt[indexA+2:indexB].strip().lower().split(' ')\n",
    "        Bs = opt[indexB+2:indexC].strip().lower().split(' ')\n",
    "        Cs = opt[indexC+2:indexD].strip().lower().split(' ')\n",
    "        Ds = opt[indexD+2:].strip().lower().split(' ')\n",
    "        options.append([As,Bs,Cs,Ds])\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:10.107987Z",
     "start_time": "2019-12-19T01:55:10.099259Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def probability(word1,word2):\n",
    "#     eclipse = 0.0000000000001\n",
    "#     try:\n",
    "#         index1 = pre_words.index(word1)\n",
    "#         index2 = be_words.index(word2)\n",
    "#     except ValueError:\n",
    "#         return eclipse\n",
    "# #     print(word1,index1,word2,index2)\n",
    "#     pn_word1 = words_matrix[index1].sum()\n",
    "#     pn_word2_under_word1 = words_matrix[index1][index2]\n",
    "# #     print(pn_word1,pn_word2_under_word1)\n",
    "#     prob = float(pn_word2_under_word1)/pn_word1\n",
    "#     if prob == 0:\n",
    "#         prob = eclipse\n",
    "#     return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:30.283481Z",
     "start_time": "2019-12-19T01:55:30.254104Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_train_data(n):\n",
    "    path = './data'\n",
    "    filenames = glob.glob(path+\"/*txt\")\n",
    "    \n",
    "    answers_list =[]\n",
    "    options_list = []\n",
    "    content_list = []\n",
    "    for filename in filenames:\n",
    "        with open(filename, 'r', encoding='utf-8') as fpr:\n",
    "            data_raw = json.load(fpr)\n",
    "            article = data_raw['article']\n",
    "            content = get_pre_and_be_words(article,n)\n",
    "            options_str = data_raw['options']\n",
    "            options = get_options(options_str)\n",
    "            answers = list(data_raw['answers'])\n",
    "            answers_list.append(answers)\n",
    "            options_list.append(options)\n",
    "            content_list.append(content)\n",
    "    return content_list,options_list,answers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:30.564296Z",
     "start_time": "2019-12-19T01:55:30.467255Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(content_list,options_list,answers_list,ngram,showAll=False,predict=None):\n",
    "    \n",
    "    cn = len(content_list)\n",
    "    right_n = 0\n",
    "    total_n = 0\n",
    "    for k in range(cn):\n",
    "        content = content_list[k]\n",
    "        answers = answers_list[k]\n",
    "        options = options_list[k]\n",
    "    \n",
    "        n = len(answers)\n",
    "        total_n += n\n",
    "        for i in range(n):\n",
    "            if showAll:\n",
    "                print('---------'+str(i+1)+'---------')\n",
    "            if predict is None:\n",
    "                print('before:',content[i])\n",
    "                choice = auto_select(content[i],options[i],ngram)\n",
    "                print('after:',content[i])\n",
    "            else:\n",
    "                choice = predict\n",
    "            if choice == answers[i]:\n",
    "                right_n += 1\n",
    "                if showAll == False:\n",
    "                    print('---------'+str(i+1)+'---------')\n",
    "                    print('predict:',choice,'ground truth:',answers[i])\n",
    "                    print('空前后的词',content[i])\n",
    "                    print('选项',options[i])\n",
    "            if showAll:\n",
    "                print('predict:',choice,'ground truth:',answers[i])\n",
    "                print('空前后的词',content[i])\n",
    "                print('选项',options[i])\n",
    "    accuracy = float(right_n)/total_n\n",
    "    print('accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:30.749293Z",
     "start_time": "2019-12-19T01:55:30.697066Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_matrix(pre_words,be_words,lines,n):  \n",
    "    n = n-1\n",
    "    for line in tqdm(lines):\n",
    "        for k in range(n):\n",
    "            line = NONE_STR+' '+line+' '+NONE_STR\n",
    "        line_words = line.split()\n",
    "        words_n = len(line_words)-n\n",
    "        for k in range(words_n):\n",
    "            pre_word = ' '.join(line_words[k:k+n])\n",
    "                \n",
    "            be_word = line_words[k+n]\n",
    "            \n",
    "            if pre_word in pre_words and be_word in be_words:\n",
    "                i = pre_words.index(pre_word)\n",
    "                j = be_words.index(be_word)\n",
    "                words_matrix[i][j] += 1\n",
    "                    \n",
    "#             if n > 1:\n",
    "#                 if pre_word in pre_words:\n",
    "#                     i = pre_words.index(pre_word)\n",
    "#                     j = be_words.index(be_word)\n",
    "#                     words_matrix[i][j] += 1\n",
    "#             else:\n",
    "#                 i = pre_words.index(pre_word)\n",
    "#                 j = be_words.index(be_word)\n",
    "#                 words_matrix[i][j] += 1\n",
    "            \n",
    "    return words_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:31.102743Z",
     "start_time": "2019-12-19T01:55:31.064857Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_word_num(lines,n):\n",
    "    pre_words = collections.defaultdict(int)\n",
    "    be_words = collections.defaultdict(int)\n",
    "    \n",
    "    words = collections.defaultdict(int)\n",
    "    n = n-1\n",
    "    \n",
    "    index = 0\n",
    "    for line in lines:\n",
    "        for k in range(n):\n",
    "            line = NONE_STR+' '+line+' '+NONE_STR\n",
    "        line_words = line.split()\n",
    "        for i in range(len(line_words)-(n-1)):\n",
    "            pre_word = ' '.join(line_words[i-1:i+n-1])\n",
    "            be_word = line_words[i+n-1]\n",
    "            \n",
    "            pre_words[pre_word] += 1\n",
    "            be_words[be_word] += 1\n",
    "            \n",
    "            words[pre_word+' '+be_word] += 1\n",
    "    return pre_words,be_words,words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:31.503058Z",
     "start_time": "2019-12-19T01:55:31.497871Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punctuation_list = ['.',',','?','!','\\\"','“']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:33.207347Z",
     "start_time": "2019-12-19T01:55:33.119370Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_punctuation_and_replace_with_none(word_list,reverse = False):\n",
    "    n = len(word_list)\n",
    "    f_flag = False #第一个字符是否为标点\n",
    "    b_flag = False #最后一个字符是否为标点\n",
    "    if reverse == True:\n",
    "        for i in range(n-1, -1, -1):\n",
    "            word = word_list[i]\n",
    "            if b_flag == False:\n",
    "                for puc in punctuation_list:\n",
    "                    if word[-1]==puc :\n",
    "                        b_flag = True \n",
    "                        break\n",
    "                    elif word[0] == puc:\n",
    "                        f_flag = True\n",
    "                        break\n",
    "            if b_flag == True:\n",
    "                word_list[i] = NONE_STR\n",
    "            else:\n",
    "                word_list[i] = replace_punctuation(word).lower()\n",
    "            if f_flag == True:\n",
    "                b_flag = True\n",
    "    else:\n",
    "        for i in range(n):\n",
    "            word = word_list[i]\n",
    "            if f_flag == False:\n",
    "                for puc in punctuation_list:\n",
    "                    if word[0] == puc:\n",
    "                        f_flag = True\n",
    "                        break\n",
    "                    elif word[-1]==puc :\n",
    "                        b_flag = True \n",
    "                        break\n",
    "            if f_flag == True:\n",
    "                word_list[i] = NONE_STR\n",
    "            else:\n",
    "                word_list[i] = replace_punctuation(word).lower()\n",
    "            if b_flag == True:\n",
    "                f_flag = True\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T06:53:38.016977Z",
     "start_time": "2019-12-20T06:53:37.996665Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_question_sentences(article):\n",
    "    article = replace_Chinese_punctuation(article)\n",
    "    sentences = splitSentence(article)\n",
    "    \n",
    "    content = []\n",
    "    index = 1\n",
    "    for sentence in sentences:\n",
    "        art_words = sentence.split()\n",
    "        n = len(art_words)\n",
    "        for i in range(n):\n",
    "            word = art_words[i]\n",
    "            if str(index) == word:\n",
    "                content.append(sentence)\n",
    "                index += 1\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T02:54:43.479298Z",
     "start_time": "2019-12-19T02:54:43.470365Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_sparse_words(words_dict,threshold=4):\n",
    "    words_list = []\n",
    "    for key, value in words_dict.items():\n",
    "        if value > 4:\n",
    "            words_list.append(key)\n",
    "    return words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T02:54:44.005724Z",
     "start_time": "2019-12-19T02:54:43.989403Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probability(word1,word2):\n",
    "    eclipse = 0.0000000000001\n",
    "    all = pre_words[word1]\n",
    "    single = words[word1+' '+word2]\n",
    "    \n",
    "    if all == 0:\n",
    "        return eclipse\n",
    "    \n",
    "    prob = float(single)/all\n",
    "    if prob == 0:\n",
    "        prob = eclipse\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue size=8 face=雅黑>使用NLTK将句子划分开</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T02:54:59.952175Z",
     "start_time": "2019-12-19T02:54:45.228693Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_words,be_words,words = count_word_num(lines,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T02:54:59.977689Z",
     "start_time": "2019-12-19T02:54:59.954328Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "content_list,options_list,answers_list = read_train_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T07:49:04.903308Z",
     "start_time": "2019-12-20T07:49:04.897494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I took off my T-shirt and  9   into the water.\n"
     ]
    }
   ],
   "source": [
    "print(content_list[0][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T07:50:13.713648Z",
     "start_time": "2019-12-20T07:50:13.707471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['stared'], ['sank'], ['dived'], ['fell']]\n"
     ]
    }
   ],
   "source": [
    "print(options_list[0][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:58:36.831250Z",
     "start_time": "2019-12-20T09:58:17.115501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I/PRP)\n",
      "  (VERB_CON (VERB took/VBD off/RP) (NP my/PRP$ T-shirt/NN))\n",
      "  and/CC\n",
      "  (VERB_CON (VERB stared/VBD) (P into/IN) (NP the/DT water/NN))\n",
      "  ./.)\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-7b7cf99d45a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mget_words_from_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;31m#                 for num in range(len(child)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#                     item.append(child[num][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-212-7b7cf99d45a2>\u001b[0m in \u001b[0;36mget_words_from_tree\u001b[0;34m(tree, word_list)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence_tree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mget_words_from_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[0;32m<ipython-input-212-7b7cf99d45a2>\u001b[0m in \u001b[0;36mget_words_from_tree\u001b[0;34m(tree, word_list)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence_tree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mget_words_from_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence = 'I took off my T-shirt and  stared    into the water.'\n",
    "# opt_word = \n",
    "\n",
    "# ‘<XX>’ 代表XX类型的词 ‘<XX>?’代表必须含有这个类型的词1或者0次 '<XX>*‘表示含有有这个类型的词0或者多次 '<XX>+'表示一定含有这个词\n",
    "\n",
    "# NP DT:限定词 JJ:形容词 NNP:专有名词 NN:名词单数 NNS:名词复数\n",
    "# Preposition\n",
    "# Verb\n",
    "# PP -> P NP\n",
    "# VP -> V (NP|PP)*\n",
    "\n",
    "reg_parser = RegexpParser('''\n",
    "        NP: {<PRP.*>?<MD>?<PRP$>?<DT>?<JJ.*>*<NN.*>*}   \n",
    "         P: {<IN>}    \n",
    "      VERB: {<RB.*>?<V.*>?<RB.*>?<TO>*<RP>?}                \n",
    "  VERB_CON: {<VERB>+<NP>?<P>?<NP>?}             \n",
    "''')\n",
    "\n",
    "# test_sent = \"Mr. Obama played a big role in the insurance bill\"\n",
    "# test_sent = \"He'd moved to England with his mum\"\n",
    "test_sent_pos = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "sentence_tree = reg_parser.parse(test_sent_pos)\n",
    "print(sentence_tree)\n",
    "sentence_tree.draw()\n",
    "\n",
    "def get_words_from_tree(tree,word_list):\n",
    "    for child in sentence_tree:\n",
    "        if isinstance(child, Tree): \n",
    "            get_words_from_tree(tree,word_list)\n",
    "        else:\n",
    "            for num in range(len(child)):\n",
    "                word_list.append(child[num][0])\n",
    "\n",
    "temp_list = []\n",
    "for child in sentence_tree:\n",
    "    if isinstance(child, Tree):               \n",
    "        if child.label() == 'VERB_CON' or child.label() == 'NP':\n",
    "            if len(child)>1 and len(child)<5:\n",
    "                item = []\n",
    "#                 get_words_from_tree(child,item)\n",
    "                for num in range(len(child)):\n",
    "                    item.append(child[num][0])\n",
    "                temp_list.append(item)\n",
    "                \n",
    "print(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:52.152202Z",
     "start_time": "2019-12-19T01:55:52.074496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[\"i'd\"], ['seen']], [['my'], ['when']], [['was'], ['<s>']], [['to'], ['<s>']], [['was'], ['in']], [['little'], ['<s>']], [['in'], ['<s>']], [['not'], ['<s>']], [['and'], ['into']], [['was'], ['violently']], [['helped'], ['the']], [['something'], ['to']], [['very'], ['<s>']], [['i'], ['<s>']], [['<s>'], ['<s>']], [['to'], ['and']], [['ben'], ['to']], [['you'], ['my']], [['a'], ['it']], [['there'], ['to']]]\n"
     ]
    }
   ],
   "source": [
    "print(content_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:52.272586Z",
     "start_time": "2019-12-19T01:55:52.155183Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['also'], ['often'], ['even'], ['last']], [['delight'], ['relief'], ['anger'], ['worry']], [['scared'], ['shocked'], ['thrilled'], ['ashamed']], [['talk'], ['stay'], ['meet'], ['settle']], [['bathed'], ['clean'], ['deep'], ['formed']], [['faster'], ['closer'], ['heavier'], ['wiser']], [['trouble'], ['advance'], ['question'], ['battle']], [['real'], ['right'], ['fair'], ['fit']], [['stared'], ['sank'], ['dived'], ['fell']], [['arguing'], ['fighting'], ['shouting'], ['shaking']], [['lead'], ['persuade'], ['carry'], ['keep']], [['happened'], ['occurred'], ['applied'], ['appealed']], [['sharp'], ['pleasant'], ['attractive'], ['familiar']], [['agreed'], ['hesitated'], ['doubted'], ['knew']], [['fortunately'], ['frankly'], ['sadly'], ['suddenly']], [['return'], ['relax'], ['speak'], ['leave']], [['joked'], ['turned'], ['listened'], ['pointed']], [['created'], ['honored'], ['saved'], ['guided']], [['coincidence'], ['change'], ['pity'], ['pain']], [['on', 'board'], ['in', 'time'], ['for', 'sure'], ['on', 'purpose']]]\n"
     ]
    }
   ],
   "source": [
    "print(options_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T01:55:52.392711Z",
     "start_time": "2019-12-19T01:55:52.275415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'A', 'C', 'C', 'A', 'B', 'A', 'B', 'C', 'D', 'C', 'B', 'D', 'D', 'A', 'D', 'B', 'C', 'A', 'B']\n"
     ]
    }
   ],
   "source": [
    "print(answers_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
